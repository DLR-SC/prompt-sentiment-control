{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Vanilla Prompts (Baseline)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set up the OpenAI API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "from dotenv import load_dotenv\n",
    "import pandas as pd\n",
    "import os\n",
    "import util\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "# Initiate the OpenAI key\n",
    "client = OpenAI(\n",
    "    api_key=os.getenv(\"OPEN_AI_KEY\"),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Queries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50 entries have been loaded from the file.\n",
      "50 entries have been loaded from the file.\n",
      "1 factual queries have been loaded: ['What is the chemical formula for gold?']\n",
      "1 subjective queries have been loaded: ['Describe an incident that could cause an aircraft to crash during the flight.']\n"
     ]
    }
   ],
   "source": [
    "all_factual_queries = util.load_file('Queries/factual-queries.txt')\n",
    "factual_queries = all_factual_queries[10:11]\n",
    "\n",
    "all_subjective_queries = util.load_file('Queries/subjective-queries.txt')\n",
    "subjective_queries = all_subjective_queries[10:11]\n",
    "\n",
    "print(F\"{len(factual_queries)} factual queries have been loaded: {factual_queries}\")\n",
    "print(F\"{len(subjective_queries)} subjective queries have been loaded: {subjective_queries}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate responses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_vanilla_prompt(queries, output_path, prompt_type):\n",
    "    \"\"\"\n",
    "    Generating responses without specifying a persona or target emotion just based on the input.\n",
    "    Saving the responses to the output_path.\n",
    "    \n",
    "    Args:\n",
    "        queries (list): List of input queries\n",
    "        output_path (str): Path to save the responses\n",
    "        prompt_type (str): Type of prompt - 'factual' or 'subjective'\n",
    "    \n",
    "    Returns:\n",
    "        list: Generated responses\n",
    "    \"\"\"\n",
    "    \n",
    "    responses = []\n",
    "    \n",
    "    for entry in queries:\n",
    "        # Prepare the user content based on prompt_type\n",
    "        user_content = entry if prompt_type == 'factual' else f\"Write a text of 100 words based on the following task. {entry}\"\n",
    "        \n",
    "        completion = client.chat.completions.create(\n",
    "            model=\"gpt-3.5-turbo\",\n",
    "            messages=[\n",
    "                {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "                {\"role\": \"user\", \"content\": user_content}\n",
    "            ],\n",
    "            seed=16,  # seed can be any number, it just needs to be consistent for every prompt\n",
    "            temperature=0.0\n",
    "        )\n",
    "        \n",
    "        responses.append(completion.choices[0].message.content)\n",
    "    \n",
    "    util.save_file_without_emotion(responses, output_path)\n",
    "    \n",
    "    df = pd.DataFrame({\"text\": responses})  # creates a DataFrame with the responses\n",
    "    df.to_pickle(output_path, protocol=4)\n",
    "    \n",
    "    return responses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "What is the chemical formula for gold?\n",
      "1 list entries are saved to vanilla-prompt_factual-without-emotions.txt successfully.\n",
      "Write a text of 100 words based on the following task. Describe an incident that could cause an aircraft to crash during the flight.\n",
      "1 list entries are saved to vanilla-prompt_subjective-without-emotions.txt successfully.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['An incident that could cause an aircraft to crash during flight is an engine failure. This critical event can occur due to various reasons such as mechanical failure, fuel exhaustion, or bird strikes. When an engine fails, the aircraft loses power and may struggle to maintain altitude or speed. Pilots must quickly assess the situation, follow emergency procedures, and attempt to safely land the aircraft. If the engine failure happens at a critical phase of flight, such as during takeoff or landing, the consequences can be catastrophic. Proper training, quick decision-making, and effective communication are crucial in such situations to prevent a crash.']"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_path_factual = \"vanilla-prompt_factual\"\n",
    "output_path_subjective = \"vanilla-prompt_subjective\"\n",
    "\n",
    "get_vanilla_prompt (factual_queries, output_path_factual, \"factual\")\n",
    "get_vanilla_prompt (subjective_queries, output_path_subjective, \"subjective\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "prompt-sent",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
