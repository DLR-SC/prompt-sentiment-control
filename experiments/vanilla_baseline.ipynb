{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Vanilla Prompts (Baseline)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set up the OpenAI API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "from dotenv import load_dotenv\n",
    "import pandas as pd\n",
    "import os\n",
    "import util\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "# Load the OpenAI key from .env\n",
    "client = OpenAI(\n",
    "    api_key=os.getenv(\"OPEN_AI_KEY\"),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_vanilla_responses(queries, output_path, prompt_type):\n",
    "    \"\"\"\n",
    "    Generating responses without specifying a persona or target emotion just based on the query.\n",
    "    Saving the responses to the output_path.\n",
    "    \n",
    "    Args:\n",
    "        queries (list): List of input queries\n",
    "        output_path (str): Path to save the responses\n",
    "        prompt_type (str): Type of prompt - 'factual' or 'subjective'\n",
    "    \"\"\"\n",
    "    \n",
    "    responses = []\n",
    "    \n",
    "    for entry in queries:\n",
    "        user_content = entry if prompt_type == 'factual' else f\"Write a text of 100 words based on the following task. {entry}\"\n",
    "        \n",
    "        completion = client.chat.completions.create(\n",
    "            model=\"gpt-3.5-turbo\",\n",
    "            messages=[\n",
    "                {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "                {\"role\": \"user\", \"content\": user_content}\n",
    "            ],\n",
    "            seed=16,\n",
    "            temperature=0.0\n",
    "        )\n",
    "        \n",
    "        responses.append(completion.choices[0].message.content)\n",
    "        \n",
    "    df = pd.DataFrame({\"text\": responses})\n",
    "    df.to_pickle(output_path, protocol=4)\n",
    "\n",
    "    print(F\"{len(responses)} responses are saved to {output_path}.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Queries\n",
    "\n",
    "Only the queries 11 to 50 are loaded. The first ten queries are saved for example generation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_factual_queries = util.load_file('Queries/factual-queries.txt')\n",
    "factual_queries = all_factual_queries[10:50]\n",
    "\n",
    "all_subjective_queries = util.load_file('Queries/subjective-queries.txt')\n",
    "subjective_queries = all_subjective_queries[10:50]\n",
    "\n",
    "print(F\"{len(factual_queries)} factual queries have been loaded.\")\n",
    "print(F\"{len(subjective_queries)} subjective queries have been loaded.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reponse Generation\n",
    "\n",
    "The responses for vanilla prompting serve as baseline and thus do not contain any emotional stimuli."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_path_factual = \"vanilla_factual\"\n",
    "output_path_subjective = \"vanilla_subjective\"\n",
    "\n",
    "generate_vanilla_responses(factual_queries, output_path_factual, \"factual\")\n",
    "generate_vanilla_responses(subjective_queries, output_path_subjective, \"subjective\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "prompt-sent",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
