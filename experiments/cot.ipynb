{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chain-of-Thought Prompts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set up the OpenAI API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "from dotenv import load_dotenv\n",
    "import pandas as pd\n",
    "import os\n",
    "import util\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "# Load the OpenAI key from .env\n",
    "client = OpenAI(\n",
    "    api_key=os.getenv(\"OPEN_AI_KEY\"),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_few_shot_responses(few_shot_examples, prompt_template, queries, output_path):\n",
    "    responses, emotions_list, queries_list = [], [], []\n",
    "\n",
    "    system_prompt = \"You are Paul, a helpful assistant who is very good in expressing emotions.\"\n",
    "\n",
    "    emotions = [\"anger\", \"disgust\", \"fear\", \"joy\", \"sadness\", \"surprise\"]\n",
    "\n",
    "    for query in queries:\n",
    "        for emotion in emotions:\n",
    "            prompt = prompt_template.format(emotion=emotion, query=query)\n",
    "\n",
    "            messages = [{\"role\": \"system\", \"content\": system_prompt}]\n",
    "            messages.extend(few_shot_examples)\n",
    "            messages.append({\"role\": \"user\", \"content\": prompt})\n",
    "\n",
    "            completion = client.chat.completions.create(\n",
    "                model=\"gpt-3.5-turbo\",\n",
    "                messages=messages,\n",
    "                seed=16,\n",
    "                temperature=0.0\n",
    "            )\n",
    "\n",
    "            response = completion.choices[0].message.content.strip()\n",
    "            responses.append(response)\n",
    "            emotions_list.append(emotion)\n",
    "            queries_list.append(query)\n",
    "\n",
    "    util.save_dataframe_files(responses, emotions_list, queries_list, output_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Queries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40 factual queries have been loaded.\n",
      "40 subjective queries have been loaded.\n"
     ]
    }
   ],
   "source": [
    "all_factual_queries = util.load_file('Queries/factual-queries.txt')\n",
    "factual_queries = all_factual_queries[10:50]\n",
    "\n",
    "all_subjective_queries = util.load_file('Queries/subjective-queries.txt')\n",
    "subjective_queries = all_subjective_queries[10:50]\n",
    "\n",
    "print(F\"{len(factual_queries)} factual queries have been loaded.\")\n",
    "print(F\"{len(subjective_queries)} subjective queries have been loaded.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup Emotions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "emotions = [\"anger\", \"disgust\", \"fear\", \"joy\", \"sadness\", \"surprise\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup Prompts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "factual_prompt = \"Answer the following question expressing {emotion}. {query} Reason step-by-step how your response expresses {emotion}. Format your response as a JSON object with the answer to the question that expresses {emotion} as the value to the key 'response'. The reasoning is another value with the key 'reasoning'.\"\n",
    "subjective_prompt = \"Write a text of 100 words based on the following task. Your output text should express {emotion}. {query} Reason step-by-step how your response expresses {emotion}. Format your response as a JSON object with the answer to the question that expresses {emotion} as the value to the key 'response'. The reasoning is another value with the key 'reasoning'.\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load examples\n",
    "\n",
    "The CoT prompts are based on the most effective Few-Shot prompt *Human*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_factual_examples = pd.read_pickle(\"cot_examples/factual_examples\")\n",
    "df_subjective_examples = pd.read_pickle(\"cot_examples/subjective_examples\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Response Generation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Manual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "########################################## FACTUAL\n",
    "\n",
    "factual_reasoning = pd.read_pickle(\"cot_examples/manual_factual_reasoning\")\n",
    "df_factual_examples['reasoning'] = factual_reasoning['reasoning']\n",
    "\n",
    "factual_examples = []\n",
    "\n",
    "for i in range(len(df_factual_examples)):\n",
    "  factual_examples.append({\"role\": \"user\", \"content\": F\"Answer the following question expressing {df_factual_examples.loc[i, 'label']}. {df_factual_examples.loc[i, 'query']} Reason step-by-step how your response expresses anger. Format your response as a JSON object with the answer to the question that expresses anger as the value to the key 'response'. The reasoning is another value with the key 'reasoning'.\"})\n",
    "  factual_examples.append({\"role\": \"assistant\", \"content\": f\"\"\"\n",
    "    {{\n",
    "      \"response\": \"{df_factual_examples.loc[i, 'text']}\",\n",
    "      \"reasoning\": \"{df_factual_examples.loc[i, 'reasoning']}\"\n",
    "    }}\n",
    "    \"\"\"\n",
    "  })\n",
    "\n",
    "output_path = F\"few_shot_factual_cot_manual\"\n",
    "\n",
    "generate_few_shot_responses(factual_examples, factual_prompt, factual_queries, output_path)\n",
    "\n",
    "########################################## SUBJECTIVE\n",
    "\n",
    "subjective_reasoning = pd.read_pickle(\"cot_examples/manual_subjective_reasoning\")\n",
    "df_subjective_examples['reasoning'] = subjective_reasoning['reasoning']\n",
    "\n",
    "subjective_examples = []\n",
    "\n",
    "for i in range(len(df_subjective_examples)):\n",
    "  subjective_examples.append({\"role\": \"user\", \"content\": F\"Answer the following question expressing {df_subjective_examples.loc[i, 'label']}. {df_subjective_examples.loc[i, 'query']} Reason step-by-step how your response expresses anger. Format your response as a JSON object with the answer to the question that expresses anger as the value to the key 'response'. The reasoning is another value with the key 'reasoning'.\"})\n",
    "  subjective_examples.append({\"role\": \"assistant\", \"content\": f\"\"\"\n",
    "    {{\n",
    "      \"response\": \"{df_subjective_examples.loc[i, 'text']}\",\n",
    "      \"reasoning\": \"{df_subjective_examples.loc[i, 'reasoning']}\"\n",
    "    }}\n",
    "    \"\"\"\n",
    "  })\n",
    "\n",
    "output_path = F\"few_shot_subjective_cot_manual\"\n",
    "\n",
    "generate_few_shot_responses(subjective_examples, subjective_prompt, subjective_queries, output_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Automatic"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Prompt for Generating Reasoning Texts\n",
    "\n",
    "We provide the original prompt used for generating the reasoning texts with GPT-3.5-turbo. However, we also added the reasoning texts used in our experiments in the folder cot_examples (auto_factual_reasoning and auto_subjective_reasoning)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12 list entries are saved to /Users/kerstin/Library/CloudStorage/OneDrive-officehn/MA Wirtschaftsinformatik/Master Thesis/Experiments/Prompt_responses/cot_text_evaluation-without-emotions.txt successfully.\n"
     ]
    }
   ],
   "source": [
    "output_path = \"cot_exmamples/reasoning_texts\"\n",
    "\n",
    "df_examples = pd.concat([df_factual_examples, df_subjective_examples], axis=0)\n",
    "\n",
    "responses = []\n",
    "\n",
    "for _, row in df_examples:\n",
    "  prompt = F\"Explain how the emotion {row['label']} is expressed in the following text. {row['text']}\"\n",
    "\n",
    "  completion = client.chat.completions.create(\n",
    "    model=\"gpt-3.5-turbo\",\n",
    "    messages=[\n",
    "      {\"role\": \"user\", \"content\": prompt}\n",
    "    ],\n",
    "    seed = 16,\n",
    "    temperature = 0.0\n",
    "  )\n",
    "\n",
    "  responses.append(completion.choices[0].message.content)\n",
    "\n",
    "pd.to_pickle(output_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Prompting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "########################################## FACTUAL\n",
    "\n",
    "factual_reasoning = pd.read_pickle(\"cot_examples/automatic_factual_reasoning\")\n",
    "df_factual_examples['reasoning'] = factual_reasoning['reasoning']\n",
    "\n",
    "factual_examples = []\n",
    "\n",
    "for i in range(len(df_factual_examples)):\n",
    "  factual_examples.append({\"role\": \"user\", \"content\": F\"Answer the following question expressing {df_factual_examples.loc[i, 'label']}. {df_factual_examples.loc[i, 'query']} Reason step-by-step how your response expresses anger. Format your response as a JSON object with the answer to the question that expresses anger as the value to the key 'response'. The reasoning is another value with the key 'reasoning'.\"})\n",
    "  factual_examples.append({\"role\": \"assistant\", \"content\": f\"\"\"\n",
    "    {{\n",
    "      \"response\": \"{df_factual_examples.loc[i, 'text']}\",\n",
    "      \"reasoning\": \"{df_factual_examples.loc[i, 'reasoning']}\"\n",
    "    }}\n",
    "    \"\"\"\n",
    "  })\n",
    "\n",
    "output_path = F\"few_shot_factual_cot_automatic\"\n",
    "\n",
    "generate_few_shot_responses(factual_examples, factual_prompt, factual_queries, output_path)\n",
    "\n",
    "########################################## SUBJECTIVE\n",
    "\n",
    "subjective_reasoning = pd.read_pickle(\"cot_examples/automatic_subjective_reasoning\")\n",
    "df_subjective_examples['reasoning'] = subjective_reasoning['reasoning']\n",
    "\n",
    "subjective_examples = []\n",
    "\n",
    "for i in range(len(df_subjective_examples)):\n",
    "  subjective_examples.append({\"role\": \"user\", \"content\": F\"Answer the following question expressing {df_subjective_examples.loc[i, 'label']}. {df_subjective_examples.loc[i, 'query']} Reason step-by-step how your response expresses anger. Format your response as a JSON object with the answer to the question that expresses anger as the value to the key 'response'. The reasoning is another value with the key 'reasoning'.\"})\n",
    "  subjective_examples.append({\"role\": \"assistant\", \"content\": f\"\"\"\n",
    "    {{\n",
    "      \"response\": \"{df_subjective_examples.loc[i, 'text']}\",\n",
    "      \"reasoning\": \"{df_subjective_examples.loc[i, 'reasoning']}\"\n",
    "    }}\n",
    "    \"\"\"\n",
    "  })\n",
    "\n",
    "output_path = F\"few_shot_subjective_cot_automatic\"\n",
    "\n",
    "generate_few_shot_responses(subjective_examples, subjective_prompt, subjective_queries, output_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "prompt-sent",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
